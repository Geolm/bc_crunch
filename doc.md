Full disclosure : this documentation has been generated by an AI

# BC_CRUNCH: Compression Algorithm Documentation (BC1 & BC4)

The `bc_crunch` library achieves its impressive lossless compression by moving beyond simple algorithms like zlib and employing a combination of **Adaptive Arithmetic Coding (AAC)**, sophisticated **Spatial Prediction**, and **Adaptive Dictionary Modeling**. This documentation breaks down how these techniques are applied to the BC1 and BC4 block formats.

## 1. The Core Engine: Adaptive Arithmetic Coding (AAC)

The entire compression process relies on Adaptive Arithmetic Coding (AAC) for entropy encoding. All other steps (delta-encoding, prediction) are designed solely to reduce the entropy of the data stream, making the AAC step maximally efficient.

* **Entropy Encoding:** Arithmetic Coding maps an entire sequence of symbols to a single fractional number, often achieving better compression than Huffman coding because it can represent symbols with fractional bits. 
* **Modeling (`range_model`):** The compressor maintains a *probability model* (a collection of counters) for every unique type of data it encounters (e.g., color red delta, index difference, etc.).
* **Adaptive Learning:** The models are **adaptive**. After encoding a symbol, the model's counters are immediately updated. This allows the compressor to dynamically learn the statistical properties of the specific texture *as it is being compressed*, which is crucial for maximizing efficiency on diverse texture data.

---

## 2. BC1 Compression (`bc1_crunch`)

A BC1 block (8 bytes) consists of two 16-bit color endpoints and one 32-bit block of 16 2-bit indices.

### A. Index Data Compression (The 32-bit Indices)

The 32-bit index pattern, which dictates the $4 \times 4$ pixel colors, is highly redundant across a texture. This is exploited using a global dictionary approach.

1.  **Global Dictionary (Top Table) Creation:**
    * The compressor first scans the entire texture and builds a **histogram** of every unique 32-bit index pattern found.
    * It selects the **Top 256 (`TABLE_SIZE`)** most frequently occurring index patterns to form the `top_table`.
    * If the macro BC_CRUNCH_USE_VECTOR_QUANTIZATION is defined in bc_crunch.c the top table is refined using vector quantization. This algorithm implements Stochastic Bit-Level K-Means Clustering to optimize a BC1 VQ table. It uses Adaptive Jittered Sampling with error-feedback to efficiently assign image blocks to centroids based on Hamming Distance. Centroids are refined via Bitwise Majority Voting, flipping bits that differ in more than 50% of assigned blocks to mathematically minimize total bit-error across iterations.
2.  **Encoding the Top Table:**
    * The `top_table` itself is compressed by encoding the **difference (delta)** between consecutive 32-bit patterns using Arithmetic Coding, which is very efficient for the small, positive differences resulting from a sorted table.
3.  **Encoding the Block Indices:**
    * For the current block, the algorithm searches the `top_table` for the index pattern that is **closest** in binary representation (measured by **Hamming distance**).
    * **Reference Index:** It encodes the index (`table_index`) of this nearest match.
    * **Mode Bit:** A single bit (`block_mode`) is encoded:
        * **`0` (Exact Match):** If the current block indices are *exactly* the same as the reference pattern.
        * **`1` (Difference):** If they differ, it computes the **XOR difference** between the current pattern and the reference. This 32-bit difference is then encoded one byte at a time using a dedicated AAC model (`table_difference`).

### B. Color Endpoint Compression (The two 16-bit colors)

Color endpoints are compressed using sophisticated **Spatial Prediction** combined with a technique to minimize color channel correlation.

1.  **Spatial Prediction (Choosing a Reference):**
    * Blocks are processed in a **zig-zag pattern** to ensure local neighborhoods are compressed together.
    * For a block's color endpoint, the compressor checks the **previous block in the row** and the **block immediately above it** to determine which provides the best predictive reference color.
    * A single bit (`color_reference`) tells the decoder which neighbor to use as the base for delta encoding. 
2.  **De-correlated Delta Encoding:**
    * The compressor calculates the difference (delta) in Red, Green, and Blue components between the current color and the chosen reference color.
    * **Green First:** The Green component delta is encoded first.
    * **R/B Prediction:** The Green delta is then used to predict the Red and Blue deltas (`dred -= dgreen/2`, `dblue -= dgreen/2`). This **de-correlates** the channels by removing the common intensity information (if G increases, R and B are likely to also increase). The smaller residual R and B deltas are then encoded, leading to higher compression ratios.

---

## 3. BC4 Compression (`bc4_crunch`)

A BC4 block (8 bytes) consists of two 8-bit color endpoints (luminance/alpha) and one 48-bit block of 16 3-bit indices.

### A. Color Endpoint Compression (The two 8-bit colors)

Prediction is key, using spatial prediction for the first endpoint and local-block prediction for the second.

1.  **Color 0 (The First Endpoint):**
    * Uses **Parallelogram Prediction** based on surrounding blocks: `Reference = Left + Up - UpLeft`.
    * The delta between the actual Color 0 and this spatial reference is calculated (with wrapping modulo 256) and encoded (`color_delta[0]`).
2.  **Color 1 (The Second Endpoint):**
    * Encoded as a delta from the **current block's Color 0**. This exploits the typical strong relationship between the two endpoints within a single BC block.

### B. Index Data Compression (The 48-bit Indices)

This involves a sophisticated blend of dictionary matching and context-aware modeling for dictionary misses.

1.  **Adaptive Dictionary (Move-to-Front - MTF):**
    * A small dictionary (`DICTIONARY_SIZE = 256`) of 48-bit index patterns is maintained.
    * It operates as a **Move-to-Front** list: when an entry is used, it is moved to index 0. This ensures the most recently and frequently used patterns have the shortest code length.
2.  **Dictionary Lookup and Mode Bit:**
    * The compressor searches the MTF dictionary for the **nearest** match based on Hamming distance.
    * **Mode Bit (`use_dict`):**
        * **`1` (Hit/Near Match):** If the nearest match is very close (`score < 4` bits different), the compressor encodes `1`, then the index of the match, and finally the **XOR difference** (16 symbols of 3 bits each). The matched pattern is moved to the front.
        * **`0` (Miss/New Pattern):** If the match is poor, the compressor encodes `0`. The current pattern is pushed to the front of the MTF dictionary.
3.  **Contextual Local Prediction (Dictionary Miss):**
    * If a pattern is not found in the dictionary, it is compressed locally using two critical levels of context:
        * **Index-Chain XOR:** The indices are processed in a zig-zag pattern within the block and encoded as the **XOR difference** from the *previously encoded index* in the chain (`block_previous ^ data`).
        * **Contextual Model Selection:** The AAC model used for this XOR difference is selected based on:
            * **Endpoint Range:** The overall contrast of the block, defined by the difference between Color 0 and Color 1 (`int_abs(color[0] - color[1])`). This difference is mapped to one of **multiple buckets** (e.g., low-contrast, medium-contrast).
            * **Previous Index Value:** The specific model within the bucket is chosen based on the value of the `block_previous` index. This high-resolution contextual modeling (which index follows which, and in which contrast environment) results in highly accurate probability estimates for the AAC encoder.